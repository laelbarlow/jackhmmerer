"""
SnakeMake workflow definition file.

"""
import os
import shutil
import glob
from snakemake.io import expand, glob_wildcards
from snakemake.utils import Paramspace
import pandas as pd


# Define list of input files.
db_fasta_files = glob.glob('resources/FASTA_Databases/*.faa')
assert len(db_fasta_files) > 0, """No FASTA files found in the
resources/FASTA_Databases directory (files must have the extension .faa)."""
query_fasta_files = glob.glob('resources/FASTA_Queries/*.faa')
assert len(query_fasta_files) > 0, """No FASTA files found in the
resources/FASTA_Queries directory (files must have the extension .faa)."""
query_names = [os.path.basename(x).rsplit('.', 1)[0] for x in query_fasta_files]


# Declare a dataframe to be a paramspace for E-value thresholds used when
# running jackhmmer.
paramspace1_file = "resources/evalue_thresholds.csv"
paramspace1 = \
Paramspace(pd.read_csv(paramspace1_file))


# Define which rules are to be run without submitting to a cluster via a job
# scheduler.
localrules: final_results, help


# Define workflow rules.

rule final_results:
    """
    Get output files from full analysis.
    """
    input:
        #'results/concat_dbs/database.ssi',
        expand('results/jackhmmer/{params}/tab_outputs/{queryfasta}.txt', \
            queryfasta = query_names, params=paramspace1.instance_patterns),
        expand('results/convert_profiles_to_fasta/{params}/aligned/{queryfasta}_jackhmmer_profile.afaa', \
            queryfasta = query_names, params=paramspace1.instance_patterns),
        expand('results/retrieve_full_length_seqs/{params}/{queryfasta}_full_length_hit_seqs.faa', \
            queryfasta = query_names, params=paramspace1.instance_patterns),
        expand('results/retrieve_full_length_seqs/{params}/{queryfasta}_full_length_top_hit_seqs.faa', \
            queryfasta = query_names, params=paramspace1.instance_patterns),
        'results/concat_dbs/database.faa.ssi',
        'results/plot_num_hits_retrieved',
        'results/workflow_diagram.pdf'

rule help:
    """
    Print list of all targets with help.
    """
    run:
        for rule in workflow.rules:
            print(rule.name)
            print(rule.docstring)


rule concat_dbs:
    """
    Concatenate database files to make one big FASTA with all the sequences to
    be searched.
    """
    input:
        db_files = db_fasta_files

    output:
        db_file = 'results/concat_dbs/database.faa'

    run:
        with open(output.db_file, 'w') as o:
            for f in input.db_files:
                with open(f) as infh:
                    for i in infh:
                        # Format EukProt sequence headers differently.
                        if i.startswith('>EP'):
                            o.write(i.split(' ')[0] + '\n')
                        # By default, insert filenames in headers.
                        elif i.startswith('>'):
                            o.write('>' + os.path.basename(f).rsplit('.', \
                            1)[0].replace(' ', '_') + '__' + i[1:].split(' ')[0] + \
                            '\n')
                        else:
                            o.write(i)


rule jackhmmer:
    """
    Run the jackhmmer program from the HMMer3 package.
    """
    input:
        db_file = 'results/concat_dbs/database.faa',
        query_file = f'resources/FASTA_Queries/{"{queryfasta}"}.faa'

    output:
        result_file = f'results/jackhmmer/{paramspace1.wildcard_pattern}/text_outputs/{"{queryfasta}"}.txt',
        tab_result_file = f'results/jackhmmer/{paramspace1.wildcard_pattern}/tab_outputs/{"{queryfasta}"}.txt',
        profile = \
        f'results/jackhmmer/{paramspace1.wildcard_pattern}/profiles/{"{queryfasta}"}_profile.stockholm',
        int_profile_dir = \
        directory(f'results/jackhmmer/{paramspace1.wildcard_pattern}/profiles/{"{queryfasta}"}_profile_intermediates')

    params:
        max_iterations = 10,
        max_seq_evalue = 0.05,
        max_domain_evalue = paramspace1.instance

    conda:
        'envs/jackhmmer.yaml'

    script:
        'scripts/jackhmmer.py'


rule convert_profiles_to_fasta:
    """
    Convert the jackhmmer output profile/alignment from stockholm to FASTA
    format.
    """
    input:
        alignment = \
        'results/jackhmmer/{params}/profiles/{queryfasta}_profile.stockholm',
        int_ali_dir = \
        'results/jackhmmer/{params}/profiles/{queryfasta}_profile_intermediates'

    output:
        aligned = \
        'results/convert_profiles_to_fasta/{params}/aligned/{queryfasta}_jackhmmer_profile.afaa',
        int_aligned_dir = \
        directory('results/convert_profiles_to_fasta/{params}/aligned/{queryfasta}_jackhmmer_profile_intermediates'),
        unaligned = \
        'results/convert_profiles_to_fasta/{params}/unaligned/{queryfasta}_jackhmmer_profile_seqs.faa',
        int_unaligned_dir = \
        directory('results/convert_profiles_to_fasta/{params}/unaligned/{queryfasta}_jackhmmer_profile_seqs_intermediates')


    conda:
        'envs/convert_profiles_to_fasta.yaml'

    script:
        'scripts/convert_profiles_to_fasta.py'


rule index_database:
    """
    Use the HMMer3 package utility esl-sfetch to construct an index for fast retrieval
    of sequences from the concatenated database FASTA file.
    """
    input:
        db_file = 'results/concat_dbs/database.faa'

    output:
        index_file = 'results/concat_dbs/database.faa.ssi'

    conda:
        'envs/jackhmmer.yaml'

    shell:
        """
        esl-sfetch --index {input.db_file}
        """


rule retrieve_full_length_seqs:
    """
    Parse jackhmmer output files and retrieve sequences for listed positive
    hits from the searched database FASTA file.
    """
    input:
        result_file = \
        'results/jackhmmer/{params}/profiles/{queryfasta}_profile.stockholm',
        database_file = 'results/concat_dbs/database.faa',
        database_index_file = 'results/concat_dbs/database.faa.ssi'

    output:
        fasta = \
        'results/retrieve_full_length_seqs/{params}/{queryfasta}_full_length_hit_seqs.faa',
        top_hit_fasta = \
        'results/retrieve_full_length_seqs/{params}/{queryfasta}_full_length_top_hit_seqs.faa',

    conda:
        'envs/jackhmmer.yaml'

    script:
        'scripts/retrieve_full_length_seqs.py'


rule plot_num_hits_retrieved:
    """
    Plot the number of hits retrieved from each taxonomic group of interest.
    """
    input:
        genome_id_taxon_csv = 'resources/genome_ids_by_taxon.csv',
        top_hit_fasta = \
        expand('results/retrieve_full_length_seqs/{params}/{queryfasta}_full_length_top_hit_seqs.faa',\
            queryfasta = query_names, params=paramspace1.instance_patterns)

    output:
        plot_dir = directory('results/plot_num_hits_retrieved')

    conda:
        'envs/plot_num_hits_retrieved.yaml'

    script:
        'scripts/plot_num_hits_retrieved.py'


rule plot_workflow:
    """
    Plot the snakemake workflow defined in the Snakefile file.
    """
    output:
        pdf = 'results/workflow_diagram.pdf',
        png = 'results/workflow_diagram.png'
    shell: 
        #'snakemake --cores 1 -p --rulegraph | dot -Tpdf > {output}'
        #snakemake --cores 1 -p --filegraph | dot -Tpdf > {output.pdf} && \
        #snakemake --cores 1 -p --filegraph | dot -Tpng > {output.png}
        """
        snakemake --cores 1 -p --rulegraph | dot -Tpdf > {output.pdf} && \
        snakemake --cores 1 -p --rulegraph | dot -Tpng > {output.png}
        """

